{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/logan/Documents/projects/repos/function-approximation/venv/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model approximates the function f(x) = 1/1+e^-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def int_to_64bit_list(number):\n",
    "    binary_str = format(number, '064b')\n",
    "    return [int(bit) for bit in binary_str]\n",
    "\n",
    "def float_to_64bit_list(f):\n",
    "    packed = struct.pack('!d', f)\n",
    "    bits = ''.join(f'{byte:08b}' for byte in packed)\n",
    "    return [int(bit) for bit in bits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "function = lambda x: math.sin(x)\n",
    "\n",
    "ints = [x for x in range(10_000)]\n",
    "\n",
    "input = [int_to_64bit_list(x) for x in ints]\n",
    "\n",
    "output = [float_to_64bit_list(function(x)) for x in ints]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor(input)\n",
    "t[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.labels = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()  \n",
    "        self.layer1 = nn.Linear(64, 256) # 64 bits in\n",
    "        self.layer2 = nn.Linear(256, 256 * 5)  \n",
    "        self.output = nn.Linear(256 * 5, 64) # 64 bits out\n",
    "\n",
    "    def forward(self, x):\n",
    "        # try relu to begin with\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 148.9356689453125\n",
      "Loss: 148.76669311523438\n",
      "Loss: 148.60240173339844\n",
      "Loss: 148.262939453125\n",
      "Loss: 147.93243408203125\n",
      "Loss: 147.65029907226562\n",
      "Loss: 147.498779296875\n",
      "Loss: 147.831298828125\n",
      "Loss: 146.85520935058594\n",
      "Loss: 146.63583374023438\n",
      "Loss: 145.88592529296875\n",
      "Loss: 145.81008911132812\n",
      "Loss: 145.4483642578125\n",
      "Loss: 145.20248413085938\n",
      "Loss: 146.6939697265625\n",
      "Loss: 145.1061248779297\n",
      "Loss: 145.39105224609375\n",
      "Loss: 143.91952514648438\n",
      "Loss: 143.70062255859375\n",
      "Loss: 143.79530334472656\n",
      "Loss: 145.66278076171875\n",
      "Loss: 146.73123168945312\n",
      "Loss: 145.22755432128906\n",
      "Loss: 143.8217315673828\n",
      "Loss: 145.0723876953125\n",
      "Loss: 146.39353942871094\n",
      "Loss: 144.2838897705078\n",
      "Loss: 142.37893676757812\n",
      "Loss: 143.2325897216797\n",
      "Loss: 142.34799194335938\n",
      "Loss: 143.06533813476562\n",
      "Loss: 143.3657684326172\n",
      "Loss: 143.36524963378906\n",
      "Loss: 141.36968994140625\n",
      "Loss: 141.3603057861328\n",
      "Loss: 143.22479248046875\n",
      "Loss: 144.58197021484375\n",
      "Loss: 141.54196166992188\n",
      "Loss: 140.1295166015625\n",
      "Loss: 141.23504638671875\n",
      "Loss: 140.9772186279297\n",
      "Loss: 139.41290283203125\n",
      "Loss: 141.7923126220703\n",
      "Loss: 142.14480590820312\n",
      "Loss: 140.00546264648438\n",
      "Loss: 141.3205108642578\n",
      "Loss: 138.78790283203125\n",
      "Loss: 139.36929321289062\n",
      "Loss: 141.59588623046875\n",
      "Loss: 147.34988403320312\n",
      "Loss: 144.2181854248047\n",
      "Loss: 142.67279052734375\n",
      "Loss: 140.63499450683594\n",
      "Loss: 139.47589111328125\n",
      "Loss: 137.576171875\n",
      "Loss: 138.50048828125\n",
      "Loss: 140.11077880859375\n",
      "Loss: 143.45843505859375\n",
      "Loss: 141.9853515625\n"
     ]
    }
   ],
   "source": [
    "training_dataset = Data(input, output)\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset,batch_size=256)\n",
    "\n",
    "model = Model().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for data in training_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss_size = loss(outputs, labels.to(device))\n",
    "        loss_size.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss_size.item()}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7785e-01, -4.7360e+00,  5.8760e-01,  6.0990e-01,  7.5151e-01,\n",
      "         6.5074e-01,  6.2571e-01,  5.9408e-01,  6.0190e-01,  4.5404e-01,\n",
      "         1.0964e-01, -5.3351e-01,  9.9573e-02,  6.1304e-03,  2.3560e-02,\n",
      "         4.0875e-02,  8.3050e-02,  2.6840e-01,  2.3909e-01, -9.4117e-02,\n",
      "        -6.5678e-02,  1.3150e-01,  9.8387e-02,  9.9108e-02,  1.1590e-01,\n",
      "         3.9549e-02,  1.0780e-01,  2.8574e-01, -1.4106e-01, -1.4607e-01,\n",
      "         1.6567e-01, -2.0342e-01,  1.0628e-01,  1.2744e-02,  5.7347e-02,\n",
      "        -2.0378e-01,  1.4350e-01,  2.0978e-01, -1.7601e-01,  9.9285e-02,\n",
      "         1.2650e-01,  2.1908e-01, -1.2678e-01,  1.3858e-01, -1.1783e-01,\n",
      "         2.1543e-01,  5.1218e-02,  4.2658e-02, -4.9893e-02, -1.9746e-01,\n",
      "        -3.4787e-01, -1.4053e-01, -1.9032e-04, -7.1840e-02, -7.0026e-02,\n",
      "        -6.0925e-03, -1.7909e-02, -1.3124e-01, -3.1149e-02,  7.5167e-02,\n",
      "        -1.8330e-01,  4.2943e-02,  1.4329e-01,  1.7939e-02], device='mps:0')\n",
      "tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  val = torch.tensor(input[500], dtype=torch.float32).to(device)\n",
    "  answer = torch.tensor(output[500], dtype=torch.float32).to(device)\n",
    "\n",
    "  outputs = model(val)  # Get predictions from the model.\n",
    "  print(outputs.data)\n",
    "  print(answer)\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
