{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the input number to a list of 64 bits.\n",
    "# this is the input to the model\n",
    "\n",
    "def int_to_64bit_list(number):\n",
    "    binary_str = format(number, '064b')\n",
    "    return [int(bit) for bit in binary_str]\n",
    "\n",
    "ints = [x for x in range(1, 1_000_000)]\n",
    "\n",
    "input_data = [int_to_64bit_list(x) for x in ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a helper class to load the data into the model\n",
    "class Data(Dataset):\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the machine learning model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "          nn.Linear(64, 64 * 5), # 64 bits in\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64 * 5, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32) # 1 value out\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "          nn.Linear(32, 64), # 1 value in\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 64 * 2),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64 * 2, 64) # 64 bits out\n",
    "        )\n",
    "\n",
    "    # this is the forward pass. it takes the input and returns the output\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.07750330865383148\n",
      "Loss: 0.07397493720054626\n",
      "Loss: 0.06241390481591225\n",
      "Loss: 0.05228934809565544\n",
      "Loss: 0.04308055713772774\n",
      "Loss: 0.032657381147146225\n",
      "Loss: 0.022448968142271042\n",
      "Loss: 0.014088207855820656\n",
      "Loss: 0.011028928682208061\n",
      "Loss: 0.008152117021381855\n",
      "Loss: 0.007061397656798363\n",
      "Loss: 0.001991485245525837\n",
      "Loss: 0.0001838746393332258\n",
      "Loss: 0.00015590351540595293\n",
      "Loss: 0.00011025762796634808\n",
      "Loss: 0.00011811965669039637\n",
      "Loss: 8.140669524436817e-05\n",
      "Loss: 7.858265598770231e-05\n",
      "Loss: 7.720560097368434e-05\n",
      "Loss: 7.663007272640243e-05\n",
      "Loss: 6.443342135753483e-05\n",
      "Loss: 5.719350519939326e-05\n",
      "Loss: 6.0171314544277266e-05\n",
      "Loss: 4.7612484195269644e-05\n",
      "Loss: 5.06916840095073e-05\n",
      "Loss: 4.899179839412682e-05\n",
      "Loss: 4.946672197547741e-05\n",
      "Loss: 5.116333340993151e-05\n",
      "Loss: 4.046065441798419e-05\n",
      "Loss: 4.583126792567782e-05\n",
      "Loss: 4.997431460651569e-05\n",
      "Loss: 4.8293448344338685e-05\n",
      "Loss: 3.6191759136272594e-05\n",
      "Loss: 3.5905228287447244e-05\n",
      "Loss: 2.9918017389718443e-05\n",
      "Loss: 3.528290835674852e-05\n",
      "Loss: 2.9471171728800982e-05\n",
      "Loss: 3.417717744014226e-05\n",
      "Loss: 2.757826223387383e-05\n",
      "Loss: 2.7654812583932653e-05\n",
      "Loss: 3.0106946724117734e-05\n",
      "Loss: 2.219552879978437e-05\n",
      "Loss: 2.6658695787773468e-05\n",
      "Loss: 2.2926682504476048e-05\n",
      "Loss: 2.7977854188065976e-05\n",
      "Loss: 1.9402363250264898e-05\n",
      "Loss: 3.0108081773505546e-05\n",
      "Loss: 2.1162373741390184e-05\n",
      "Loss: 2.571974619058892e-05\n",
      "Loss: 2.3514214262831956e-05\n",
      "Loss: 1.850341141107492e-05\n",
      "Loss: 2.1364430722314864e-05\n",
      "Loss: 1.9858245650539175e-05\n",
      "Loss: 2.0483574189711362e-05\n",
      "Loss: 1.8713993995334022e-05\n",
      "Loss: 1.341382539976621e-05\n",
      "Loss: 1.814665120036807e-05\n",
      "Loss: 1.7762824427336454e-05\n",
      "Loss: 1.546442035760265e-05\n",
      "Loss: 2.444893470965326e-05\n",
      "Loss: 1.7183652744279243e-05\n",
      "Loss: 1.9618169972090982e-05\n",
      "Loss: 1.5941570381983183e-05\n",
      "Loss: 1.3396846952673513e-05\n",
      "Loss: 1.2076882740075234e-05\n",
      "Loss: 1.4190884030540474e-05\n",
      "Loss: 2.047890484391246e-05\n",
      "Loss: 1.449278170184698e-05\n",
      "Loss: 1.2552053703984711e-05\n",
      "Loss: 1.321347644989146e-05\n",
      "Loss: 1.3013802345085423e-05\n",
      "Loss: 8.819290087558329e-06\n",
      "Loss: 1.850469379860442e-05\n",
      "Loss: 1.3679005860467441e-05\n",
      "Loss: 1.6527996194781736e-05\n",
      "Loss: 1.3728988051298074e-05\n",
      "Loss: 1.1102039024990518e-05\n",
      "Loss: 1.0042742360383272e-05\n",
      "Loss: 1.049539332598215e-05\n",
      "Loss: 1.3030145964876283e-05\n",
      "Loss: 1.3424072676571086e-05\n",
      "Loss: 1.1503155292302836e-05\n",
      "Loss: 1.0499365089344792e-05\n",
      "Loss: 1.3412361113296356e-05\n",
      "Loss: 1.7134027075371705e-05\n",
      "Loss: 9.935754860634916e-06\n",
      "Loss: 8.706402695679571e-06\n",
      "Loss: 8.577186235925183e-06\n",
      "Loss: 8.54787231219234e-06\n",
      "Loss: 1.0958005077554844e-05\n",
      "Loss: 6.350214789563324e-06\n",
      "Loss: 1.3711261090065818e-05\n",
      "Loss: 9.465818038734142e-06\n",
      "Loss: 1.1541822459548712e-05\n",
      "Loss: 8.259189598902594e-06\n",
      "Loss: 1.1016568350896705e-05\n",
      "Loss: 6.984053470660001e-06\n",
      "Loss: 1.1270805771346204e-05\n",
      "Loss: 8.411067028646357e-06\n",
      "Loss: 8.672937838127837e-06\n"
     ]
    }
   ],
   "source": [
    "# create the dataset and the loader\n",
    "training_dataset = Data(input_data)\n",
    "training_loader = DataLoader(training_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# create model and send it to the device, the mac gpu.\n",
    "model = Model().to(device)\n",
    "\n",
    "# mean squared error loss and the optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # learning rate and momentum are hyperparameters that can be tuned\n",
    "\n",
    "# train the model for 50 iterations\n",
    "for epoch in range(100):\n",
    "\n",
    "    # iterate over the data\n",
    "    for data in training_loader:\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run the data through the model, we need to send it to the device as well\n",
    "        out = model(inputs)\n",
    "        loss_size = loss(out, inputs)\n",
    "        loss_size.backward() # backpropagation\n",
    "        optimizer.step() # update the weights\n",
    "\n",
    "    print(f\"Loss: {loss_size}\")\n",
    "    \n",
    "    # save the model\n",
    "torch.save(model.state_dict(), f\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"model\", weights_only=False)\n",
    "model = Model().to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "val = torch.tensor(int_to_64bit_list(100), dtype=torch.float32).to(device)\n",
    "\n",
    "output = model.encoder(val)\n",
    "\n",
    "res = model.decoder(output)\n",
    "\n",
    "# convert values to binary output. 0.5 was a starting point.\n",
    "binary_tensor = (res >= 0.5).int().tolist()\n",
    "\n",
    "\n",
    "bit_string = ''.join(map(str, binary_tensor))\n",
    "number = int(bit_string, 2)\n",
    "\n",
    "assert number == 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
