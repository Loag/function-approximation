{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the input number to a list of 64 bits.\n",
    "# this is the input to the model\n",
    "\n",
    "def int_to_64bit_list(number):\n",
    "    binary_str = format(number, '064b')\n",
    "    return [int(bit) for bit in binary_str]\n",
    "\n",
    "ints = [x for x in range(1, 1_000_000)]\n",
    "\n",
    "input_data = [int_to_64bit_list(x) for x in ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a helper class to load the data into the model\n",
    "class Data(Dataset):\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the machine learning model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "          nn.Linear(64, 64 * 5), # 64 bits in\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64 * 5, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32) # 1 value out\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "          nn.Linear(32, 64), # 1 value in\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 64 * 2),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64 * 2, 64) # 64 bits out\n",
    "        )\n",
    "\n",
    "    # this is the forward pass. it takes the input and returns the output\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.07574784010648727\n",
      "Loss: 0.07287474721670151\n",
      "Loss: 0.06256505101919174\n",
      "Loss: 0.05387353152036667\n",
      "Loss: 0.04096760228276253\n",
      "Loss: 0.03476806730031967\n",
      "Loss: 0.026425348594784737\n",
      "Loss: 0.02417917363345623\n",
      "Loss: 0.018669014796614647\n",
      "Loss: 0.011933606117963791\n",
      "Loss: 0.01207087654620409\n",
      "Loss: 0.007353839930146933\n",
      "Loss: 0.004649989772588015\n",
      "Loss: 0.00028651399770751595\n",
      "Loss: 0.00010962077794829383\n",
      "Loss: 0.0001315423724008724\n",
      "Loss: 0.00011187815835000947\n",
      "Loss: 0.0001054332751664333\n",
      "Loss: 7.193471537902951e-05\n",
      "Loss: 6.71574889565818e-05\n",
      "Loss: 7.950556755531579e-05\n",
      "Loss: 6.971681432332844e-05\n",
      "Loss: 8.06220414233394e-05\n",
      "Loss: 6.880093860672787e-05\n",
      "Loss: 5.533561488846317e-05\n",
      "Loss: 5.074084401712753e-05\n",
      "Loss: 5.747174145653844e-05\n",
      "Loss: 5.5280732340179384e-05\n",
      "Loss: 4.350199014879763e-05\n",
      "Loss: 5.807401248603128e-05\n",
      "Loss: 3.904541881638579e-05\n",
      "Loss: 3.193641168763861e-05\n",
      "Loss: 4.546070340438746e-05\n",
      "Loss: 3.37510064127855e-05\n",
      "Loss: 4.05072933062911e-05\n",
      "Loss: 3.4653199691092595e-05\n",
      "Loss: 3.309425665065646e-05\n",
      "Loss: 2.7912919904338196e-05\n",
      "Loss: 3.717011713888496e-05\n",
      "Loss: 3.751700569409877e-05\n",
      "Loss: 2.7414524083724245e-05\n",
      "Loss: 2.9563318094005808e-05\n",
      "Loss: 3.4950127883348614e-05\n",
      "Loss: 2.5653331249486655e-05\n",
      "Loss: 3.13056843879167e-05\n",
      "Loss: 2.4781062165857293e-05\n",
      "Loss: 2.531356039980892e-05\n",
      "Loss: 3.678243956528604e-05\n",
      "Loss: 2.5286481104558334e-05\n",
      "Loss: 1.9639506717794575e-05\n",
      "Loss: 2.5601679226383567e-05\n",
      "Loss: 2.2287296815193258e-05\n",
      "Loss: 2.530327401473187e-05\n",
      "Loss: 1.5584324501105584e-05\n",
      "Loss: 1.8015878595178947e-05\n",
      "Loss: 2.3692227841820568e-05\n",
      "Loss: 1.831900590332225e-05\n",
      "Loss: 1.815218638512306e-05\n",
      "Loss: 1.9969575077993795e-05\n",
      "Loss: 1.4638839274994098e-05\n",
      "Loss: 1.716869701340329e-05\n",
      "Loss: 1.669573066465091e-05\n",
      "Loss: 1.5871202776907012e-05\n",
      "Loss: 1.180660638055997e-05\n",
      "Loss: 1.9792301827692427e-05\n",
      "Loss: 1.96395703824237e-05\n",
      "Loss: 1.5683546735090204e-05\n",
      "Loss: 1.1969970728387125e-05\n",
      "Loss: 1.706993134575896e-05\n",
      "Loss: 1.4637202184530906e-05\n",
      "Loss: 1.3987541933602188e-05\n",
      "Loss: 1.3203200069256127e-05\n",
      "Loss: 1.5214243830996566e-05\n",
      "Loss: 1.7160067727672867e-05\n",
      "Loss: 1.4583180018234998e-05\n",
      "Loss: 1.1150021236971952e-05\n",
      "Loss: 1.3224034773884341e-05\n",
      "Loss: 1.356830671284115e-05\n",
      "Loss: 1.3640984434459824e-05\n",
      "Loss: 1.628945756237954e-05\n",
      "Loss: 1.2813090506824665e-05\n",
      "Loss: 9.06490549823502e-06\n",
      "Loss: 8.930731382861268e-06\n",
      "Loss: 1.1164477655256633e-05\n",
      "Loss: 1.468489699618658e-05\n",
      "Loss: 1.3468782526615541e-05\n",
      "Loss: 9.786783266463317e-06\n",
      "Loss: 8.689190508448519e-06\n",
      "Loss: 1.0331640623917338e-05\n",
      "Loss: 6.826663138781441e-06\n",
      "Loss: 8.566736141801812e-06\n",
      "Loss: 8.771440661803354e-06\n",
      "Loss: 6.5128260757774115e-06\n",
      "Loss: 8.903985872166231e-06\n",
      "Loss: 7.740370165265631e-06\n",
      "Loss: 7.062420991132967e-06\n",
      "Loss: 6.452757588704117e-06\n",
      "Loss: 7.157736490626121e-06\n",
      "Loss: 1.4607883713324554e-05\n",
      "Loss: 1.1000176527886651e-05\n"
     ]
    }
   ],
   "source": [
    "# create the dataset and the loader\n",
    "training_dataset = Data(input_data)\n",
    "training_loader = DataLoader(training_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# create model and send it to the device, the mac gpu.\n",
    "model = Model().to(device)\n",
    "\n",
    "# mean squared error loss and the optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # learning rate and momentum are hyperparameters that can be tuned\n",
    "\n",
    "# train the model for 50 iterations\n",
    "for epoch in range(100):\n",
    "\n",
    "    # iterate over the data\n",
    "    for data in training_loader:\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run the data through the model, we need to send it to the device as well\n",
    "        out = model(inputs)\n",
    "        loss_size = loss(out, inputs)\n",
    "        loss_size.backward() # backpropagation\n",
    "        optimizer.step() # update the weights\n",
    "\n",
    "    print(f\"Loss: {loss_size}\")\n",
    "    \n",
    "    # save the model\n",
    "torch.save(model.state_dict(), f\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"model\", weights_only=False)\n",
    "model = Model().to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "val = torch.tensor(int_to_64bit_list(100), dtype=torch.float32).to(device)\n",
    "\n",
    "output = model.encoder(val)\n",
    "\n",
    "res = model.decoder(output)\n",
    "\n",
    "# convert values to binary output. 0.5 was a starting point.\n",
    "binary_tensor = (res >= 0.5).int().tolist()\n",
    "\n",
    "\n",
    "bit_string = ''.join(map(str, binary_tensor))\n",
    "number = int(bit_string, 2)\n",
    "\n",
    "assert number == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
